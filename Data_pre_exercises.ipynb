{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d84fe3bf",
   "metadata": {},
   "source": [
    "# Exercises: Data Preparation Case Studies\n",
    "\n",
    "The goal of the exercises below is for you to practice applying preprocessing steps correctly in a model evaluation workflow, using `Pipeline` and `Cross-Validation` to avoid data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e0c3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import mean, std, absolute\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Sklearn Preprocessing\n",
    "from sklearn.preprocessing import (\n",
    "    MinMaxScaler, StandardScaler, RobustScaler,\n",
    "    PowerTransformer, QuantileTransformer, KBinsDiscretizer,\n",
    "    PolynomialFeatures, OneHotEncoder, LabelEncoder\n",
    ")\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.experimental import enable_iterative_imputer # Needed for IterativeImputer\n",
    "\n",
    "# Sklearn Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_regression, RFE\n",
    "\n",
    "# Sklearn Modeling\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, HuberRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "\n",
    "# Sklearn Model Selection and Metrics\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score, RepeatedStratifiedKFold, RepeatedKFold,\n",
    "    GridSearchCV\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error\n",
    "\n",
    "# Sklearn Datasets\n",
    "from sklearn.datasets import make_classification, make_regression, fetch_openml, fetch_california_housing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bf49d3",
   "metadata": {},
   "source": [
    "## --- Helper Functions ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52370516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_horse_colic():\n",
    "    \"\"\"Load the Horse Colic dataset from URL and handle missing values.\"\"\"\n",
    "    url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/horse-colic.csv'\n",
    "    df = pd.read_csv(url, header=None, na_values='?')\n",
    "    # Column 23 is the outcome (surgical or not), no missing values\n",
    "    # Other columns are inputs\n",
    "    data = df.values\n",
    "    ix = [i for i in range(data.shape[1]) if i != 23]\n",
    "    X, y = data[:, ix], data[:, 23]\n",
    "    # Ensure y is integer\n",
    "    y = y.astype(int)\n",
    "    return X, y\n",
    "\n",
    "def load_sonar():\n",
    "    \"\"\"Load the Sonar dataset from URL.\"\"\"\n",
    "    url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/sonar.csv'\n",
    "    df = pd.read_csv(url, header=None)\n",
    "    data = df.values\n",
    "    X, y = data[:, :-1], data[:, -1]\n",
    "    X = X.astype('float32')\n",
    "    y = LabelEncoder().fit_transform(y.astype('str'))\n",
    "    return X, y\n",
    "\n",
    "def load_abalone():\n",
    "    \"\"\"Load the Abalone dataset from URL.\"\"\"\n",
    "    url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/abalone.csv'\n",
    "    df = pd.read_csv(url, header=None)\n",
    "    # Last column is the target (rings)\n",
    "    last_ix = len(df.columns) - 1\n",
    "    X, y = df.drop(last_ix, axis=1), df[last_ix]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fbf875",
   "metadata": {},
   "source": [
    "### Dataset Introduction: Pima Indians Diabetes\n",
    "\n",
    "This is a classic classification dataset, loaded directly from a URL. The goal is to predict whether a person has diabetes ('class' column) based on 8 medical features. \n",
    "\n",
    "An important characteristic of this dataset is that it contains invalid zero values (e.g., blood pressure = 0 in columns like 'pres', 'plas'...), which require Data Cleaning before processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72de9bc",
   "metadata": {},
   "source": [
    "## --- Problem 1: Compare the effectiveness of Scaling with KNN ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef0c381",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Problem 1: Pima Diabetes Data (Scaling) ---\")\n",
    "# 1. Load the Pima Indians Diabetes dataset from URL\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age', 'class']\n",
    "df_pima = pd.read_csv(url, header=None, names=names)\n",
    "\n",
    "# 2. Replace invalid zero values with NaN in specific columns\n",
    "cols_with_zero_nan = ['plas', 'pres', 'skin', 'insu', 'mass']\n",
    "df_pima[cols_with_zero_nan] = df_pima[cols_with_zero_nan].replace(0, np.nan)\n",
    "\n",
    "# Split X and y (y is already 0 or 1, no LabelEncoder needed)\n",
    "X_pima = df_pima.drop('class', axis=1).values\n",
    "y_pima = df_pima['class'].values\n",
    "print(\"Pima Indians Diabetes dataset loaded successfully from URL.\")\n",
    "\n",
    "# --- EXERCISE REQUIREMENTS --- \n",
    "# 1. Create 3 separate Pipelines (MinMaxScaler, StandardScaler, RobustScaler).\n",
    "# 2. Each Pipeline must include 3 steps: ('i', SimpleImputer(strategy='mean')), ('s', [Corresponding Scaler]), ('m', KNeighborsClassifier()).\n",
    "# 3. Define RepeatedStratifiedKFold (10 splits, 3 repeats, random_state=1).\n",
    "# 4. Evaluate and print the mean accuracy for all 3 pipelines.\n",
    "# 5. (Optional) Plot a boxplot to compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525c96cc",
   "metadata": {},
   "source": [
    "### Knowledge Check (Problem 1)\n",
    "\n",
    "**Question 1:** Why do we need `SimpleImputer` before `scaling` in this pipeline?\n",
    "\n",
    "**Question 2:** How is the `KNeighborsClassifier` (KNN) model affected by data scaling?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a017051d",
   "metadata": {},
   "source": [
    "## --- Problem 2: Apply Feature Selection (SelectKBest) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a813e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Problem 2: Pima Diabetes Data (SelectKBest) ---\")\n",
    "# 1. Load and 2. Process Pima data\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age', 'class']\n",
    "df_pima = pd.read_csv(url, header=None, names=names)\n",
    "cols_with_zero_nan = ['plas', 'pres', 'skin', 'insu', 'mass']\n",
    "df_pima[cols_with_zero_nan] = df_pima[cols_with_zero_nan].replace(0, np.nan)\n",
    "X_pima = df_pima.drop('class', axis=1).values\n",
    "y_pima = df_pima['class'].values # y is already 0/1\n",
    "print(\"Pima dataset loaded and processed.\")\n",
    "\n",
    "# --- EXERCISE REQUIREMENTS --- \n",
    "# 1. Create a single Pipeline that includes the following steps:\n",
    "#    a. ('i', SimpleImputer(strategy='mean'))\n",
    "#    b. ('s', SelectKBest(score_func=f_classif, k=4)) \n",
    "#    c. ('m', LogisticRegression(solver='liblinear'))\n",
    "# 2. Define RepeatedStratifiedKFold.\n",
    "# 3. Evaluate the pipeline using cross_val_score and print the mean accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceba1837",
   "metadata": {},
   "source": [
    "### Knowledge Check (Problem 2)\n",
    "\n",
    "**Question 1:** What does `f_classif` (ANOVA F-test) used in `SelectKBest` measure?\n",
    "\n",
    "**Question 2:** Why do we place `SimpleImputer` *before* `SelectKBest` in the pipeline?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2f510e",
   "metadata": {},
   "source": [
    "## --- Problem 3: Tune the number of features 'k' using GridSearchCV ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70bb4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Problem 3: Pima Diabetes Data (GridSearchCV) ---\")\n",
    "# 1. Load and process Pima data\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'insu', 'mass', 'pedi', 'age', 'class']\n",
    "df_pima = pd.read_csv(url, header=None, names=names)\n",
    "cols_with_zero_nan = ['plas', 'pres', 'skin', 'insu', 'mass']\n",
    "df_pima[cols_with_zero_nan] = df_pima[cols_with_zero_nan].replace(0, np.nan)\n",
    "X_pima = df_pima.drop('class', axis=1).values\n",
    "y_pima = df_pima['class'].values # y is already 0/1\n",
    "print(\"Pima dataset loaded and processed.\")\n",
    "\n",
    "# --- EXERCISE REQUIREMENTS --- \n",
    "# 1. Create a Pipeline similar to Problem 2, but do *not* specify 'k' in SelectKBest.\n",
    "#    (Just use: SelectKBest(score_func=f_classif)).\n",
    "# 2. Define a 'param_grid' to search for 'k'. Hint: {'s__k': list(range(1, X_pima.shape[1] + 1))}\n",
    "#    (Assuming your SelectKBest step is named 's').\n",
    "# 3. Define RepeatedStratifiedKFold.\n",
    "# 4. Create a GridSearchCV object wrapping the Pipeline, param_grid, and cv.\n",
    "# 5. Run grid_search.fit() and print the best_params_ and best_score_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df44f012",
   "metadata": {},
   "source": [
    "### Knowledge Check (Problem 3)\n",
    "\n",
    "**Question 1:** What does `param_grid = {'s__k': ...}` mean? Why the `s__` (double underscore)?\n",
    "\n",
    "**Question 2:** What is the benefit of wrapping the entire `Pipeline` in `GridSearchCV` instead of just running `GridSearchCV` on `SelectKBest` and then training the model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc75c4b7",
   "metadata": {},
   "source": [
    "### Dataset Introduction: Horse Colic\n",
    "\n",
    "This is a classification dataset containing mixed-type data (both numerical and categorical features).\n",
    "\n",
    "The goal is to predict whether a horse with colic will require surgery (column 23). Its main characteristic is the large number of missing values, marked with '?', making it an ideal case study for Imputation strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da46564",
   "metadata": {},
   "source": [
    "## --- Problem 4: Compare statistical Imputation strategies ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f5bca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Problem 4: Horse Colic Data (Statistical Imputation) ---\")\n",
    "# 1. Load the Horse Colic dataset\n",
    "X_hc, y_hc = load_horse_colic()\n",
    "print(\"Horse Colic dataset loaded successfully.\")\n",
    "\n",
    "# --- EXERCISE REQUIREMENTS --- \n",
    "# 1. Define a list of strategies: ['mean', 'median', 'most_frequent', 'constant'].\n",
    "# 2. Define RepeatedStratifiedKFold.\n",
    "# 3. Loop through each strategy:\n",
    "#    a. Create a Pipeline with (SimpleImputer(strategy=s), RandomForestClassifier()).\n",
    "#    b. Evaluate and print the mean accuracy for that strategy.\n",
    "# 4. (Optional) Plot a boxplot to compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb7df7d",
   "metadata": {},
   "source": [
    "### Knowledge Check (Problem 4)\n",
    "\n",
    "**Question 1:** When should you use the 'median' strategy instead of 'mean' for `SimpleImputer`?\n",
    "\n",
    "**Question 2:** Why is the 'most_frequent' strategy useful for the Horse Colic dataset?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1f1c17",
   "metadata": {},
   "source": [
    "## --- Problem 5: Apply and tune 'k' for KNNImputer ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1756da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Problem 5: Horse Colic Data (KNN Imputation) ---\")\n",
    "# 1. Load the Horse Colic dataset\n",
    "X_hc, y_hc = load_horse_colic()\n",
    "print(\"Horse Colic dataset loaded.\")\n",
    "\n",
    "# --- EXERCISE REQUIREMENTS --- \n",
    "# 1. Define RepeatedStratifiedKFold.\n",
    "# 2. Define a list of 'k' (neighbors) values to try: [1, 3, 5, 7, 9, 15, 21].\n",
    "# 3. Loop through each 'k' value:\n",
    "#    a. Create a Pipeline with (KNNImputer(n_neighbors=k), RandomForestClassifier()).\n",
    "#    b. Evaluate and print the mean accuracy for that 'k'.\n",
    "# 4. (Optional) Plot a boxplot to compare the results for each 'k'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66408586",
   "metadata": {},
   "source": [
    "### Knowledge Check (Problem 5)\n",
    "\n",
    "**Question 1:** How does `KNNImputer` work to fill in a missing value?\n",
    "\n",
    "**Question 2:** Looking at the chart, why might `k=1` give a worse (or more varied) result than `k=5` or `k=7`?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629386f1",
   "metadata": {},
   "source": [
    "## --- Problem 6: Apply IterativeImputer ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd6ed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Problem 6: Horse Colic Data (Iterative Imputation) ---\")\n",
    "\n",
    "# 1. Load data\n",
    "X_hc, y_hc = load_horse_colic()\n",
    "print(\"Horse Colic dataset loaded.\")\n",
    "\n",
    "# --- EXERCISE REQUIREMENTS --- \n",
    "# 1. Define RepeatedStratifiedKFold.\n",
    "# 2. Create a Pipeline with (IterativeImputer(max_iter=10, random_state=1), RandomForestClassifier()).\n",
    "# 3. Evaluate and print the mean accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466ee4e9",
   "metadata": {},
   "source": [
    "### Knowledge Check (Problem 6)\n",
    "\n",
    "**Question 1:** What is the fundamental difference between `IterativeImputer` and `SimpleImputer`/`KNNImputer`?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae2d33d",
   "metadata": {},
   "source": [
    "### Dataset Introduction: Synthetic Regression\n",
    "\n",
    "In this case study, we will not use real data but will create a \"synthetic\" dataset using `make_regression`.\n",
    "\n",
    "We will intentionally create 1000 samples, 20 features, but only 10 are informative (`n_informative=10`). The goal is to see if `GridSearchCV` with `SelectKBest` (using `mutual_info_regression`) can correctly find these 10 important features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ada111c",
   "metadata": {},
   "source": [
    "## --- Problem 7: Tune Feature Selection for a Regression problem ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4022ec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Problem 7: Synthetic Regression (Feature Selection Tuning) ---\")\n",
    "# 1. Create a synthetic regression dataset\n",
    "X_reg, y_reg = make_regression(n_samples=1000, n_features=20, n_informative=10, noise=0.1, random_state=1)\n",
    "\n",
    "# --- EXERCISE REQUIREMENTS --- \n",
    "# 1. Create a Pipeline with:\n",
    "#    a. ('s', SelectKBest(score_func=mutual_info_regression))\n",
    "#    b. ('m', LinearRegression())\n",
    "# 2. Define a 'param_grid' to find 's__k' (from 1 to 20).\n",
    "# 3. Define RepeatedKFold (for regression).\n",
    "# 4. Create a GridSearchCV, using scoring='neg_mean_absolute_error'.\n",
    "# 5. Run grid_search.fit() and print the best 'k' and best MAE (absolute(best_score_))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0864626",
   "metadata": {},
   "source": [
    "### Knowledge Check (Problem 7)\n",
    "\n",
    "**Question 1:** Why does this case study use `mutual_info_regression` and not `f_classif` (ANOVA) like in Problem 3?\n",
    "\n",
    "**Question 2:** Why do we use `scoring='neg_mean_absolute_error'` (negative MAE) instead of 'accuracy'?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b6639c",
   "metadata": {},
   "source": [
    "### Dataset Introduction: Synthetic Classification\n",
    "\n",
    "Similar to the previous case study, we create synthetic data using `make_classification`. \n",
    "\n",
    "We create 20 features, but only 10 are informative (`n_informative=10`) and 5 are redundant (`n_redundant=5`) (e.g., copies or linear combinations of informative features). The goal is to see if `RFE` (Recursive Feature Elimination) can effectively remove the redundant and irrelevant features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9b5ada",
   "metadata": {},
   "source": [
    "## --- Problem 8: Apply Recursive Feature Elimination (RFE) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22a5744",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Problem 8: Synthetic Classification (RFE) ---\")\n",
    "# 1. Create a synthetic classification dataset\n",
    "X_rfe, y_rfe = make_classification(n_samples=1000, n_features=20, n_informative=10, n_redundant=5, random_state=1)\n",
    "\n",
    "# --- EXERCISE REQUIREMENTS --- \n",
    "# 1. Define an estimator: DecisionTreeClassifier(random_state=1).\n",
    "# 2. Create a Pipeline with:\n",
    "#    a. ('rfe', RFE(estimator=estimator, n_features_to_select=10)) (use the estimator you just defined)\n",
    "#    b. ('m', DecisionTreeClassifier(random_state=1)) (as the final model)\n",
    "# 3. Define RepeatedStratifiedKFold.\n",
    "# 4. Evaluate the pipeline and print the mean accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27083d84",
   "metadata": {},
   "source": [
    "### Knowledge Check (Problem 8)\n",
    "\n",
    "**Question 1:** How does `RFE` (Recursive Feature Elimination) work?\n",
    "\n",
    "**Question 2:** What is the difference between `RFE` (a Wrapper method) and `SelectKBest` (a Filter method)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2481b355",
   "metadata": {},
   "source": [
    "### Dataset Introduction: Sonar, Mines vs. Rocks\n",
    "\n",
    "This is a binary classification dataset. The goal is to predict if an underwater object is a Mine or a Rock based on 60 sonar signals.\n",
    "\n",
    "All 60 features are numerical and range between 0 and 1. This data often does not follow a normal (Gaussian) distribution, making it a good candidate for Data Transforms like Power and Quantile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c948d4f",
   "metadata": {},
   "source": [
    "## --- Problem 9: Compare Power Transforms (Yeo-Johnson vs. Box-Cox) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4481d42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Problem 9: Sonar (Power Transform) ---\")\n",
    "# 1. Load the Sonar dataset\n",
    "X_sonar, y_sonar = load_sonar()\n",
    "print(\"Sonar dataset loaded successfully.\")\n",
    "\n",
    "# --- EXERCISE REQUIREMENTS --- \n",
    "# 1. Define RepeatedStratifiedKFold.\n",
    "# 2. Create Pipeline 1 (Yeo-Johnson):\n",
    "#    a. ('s', StandardScaler())\n",
    "#    b. ('p', PowerTransformer(method='yeo-johnson'))\n",
    "#    c. ('m', KNeighborsClassifier())\n",
    "# 3. Evaluate Pipeline 1 and print the result.\n",
    "# 4. Create Pipeline 2 (Box-Cox) (Use the corrected version from the lecture):\n",
    "#    a. ('s', StandardScaler())\n",
    "#    b. ('scale_pos', MinMaxScaler(feature_range=(1, 2))) # Ensure > 0\n",
    "#    c. ('p', PowerTransformer(method='box-cox'))\n",
    "#    d. ('m', KNeighborsClassifier())\n",
    "# 5. Evaluate Pipeline 2 and print the result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbffbbb",
   "metadata": {},
   "source": [
    "### Knowledge Check (Problem 9)\n",
    "\n",
    "**Question 1:** What is the goal of `PowerTransformer` (Yeo-Johnson, Box-Cox)?\n",
    "\n",
    "**Question 2:** What is the main difference between 'Yeo-Johnson' and 'Box-Cox'?\n",
    "\n",
    "**Question 3 (Advanced):** Why did the corrected `Box-Cox` pipeline need both `StandardScaler` and `MinMaxScaler(1, 2)`?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bae6b3e",
   "metadata": {},
   "source": [
    "## --- Problem 10: Compare Quantile Transforms (Uniform vs. Normal) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef80afac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Problem 10: Sonar (Quantile Transform) ---\")\n",
    "# 1. Load data\n",
    "X_sonar, y_sonar = load_sonar()\n",
    "print(\"Sonar dataset loaded.\")\n",
    "\n",
    "# --- EXERCISE REQUIREMENTS --- \n",
    "# 1. Define RepeatedStratifiedKFold.\n",
    "# 2. Define a list: distributions = ['uniform', 'normal'].\n",
    "# 3. Loop through each distribution:\n",
    "#    a. Create a Pipeline with (QuantileTransformer(output_distribution=dist, ...), KNeighborsClassifier()).\n",
    "#    Note: set n_quantiles=min(100, X_sonar.shape[0]-1) and random_state=1.\n",
    "#    b. Evaluate and print the mean accuracy.\n",
    "# 4. (Optional) Plot a boxplot comparing the 2 distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5fd030",
   "metadata": {},
   "source": [
    "### Knowledge Check (Problem 10)\n",
    "\n",
    "**Question 1:** How does `QuantileTransformer(output_distribution='uniform')` transform the data?\n",
    "\n",
    "**Question 2:** How does `QuantileTransformer` differ from `MinMaxScaler`, even though both can output data in the [0, 1] range?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6781dbf8",
   "metadata": {},
   "source": [
    "## --- Problem 11: Compare Discretization Strategies ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b5ed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Problem 11: Sonar (Discretization) ---\")\n",
    "# 1. Load data\n",
    "X_sonar, y_sonar = load_sonar()\n",
    "print(\"Sonar dataset loaded.\")\n",
    "\n",
    "# --- EXERCISE REQUIREMENTS --- \n",
    "# 1. Define RepeatedStratifiedKFold.\n",
    "# 2. Define a list: strategies_disc = ['uniform', 'quantile', 'kmeans'].\n",
    "# 3. Loop through each strategy:\n",
    "#    a. Create a Pipeline with (KBinsDiscretizer(n_bins=5, encode='ordinal', strategy=strat_disc), KNeighborsClassifier()).\n",
    "#    b. Evaluate and print the mean accuracy.\n",
    "# 4. (Optional) Plot a boxplot comparing the 3 strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e7d721",
   "metadata": {},
   "source": [
    "### Knowledge Check (Problem 11)\n",
    "\n",
    "**Question 1:** What does `KBinsDiscretizer` (discretization) turn numerical data into?\n",
    "\n",
    "**Question 2:** What is the difference between the 'uniform' and 'quantile' strategies?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd74293",
   "metadata": {},
   "source": [
    "## --- Problem 12: Apply PolynomialFeatures ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab3b917",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Problem 12: Sonar (Polynomial Features) ---\")\n",
    "# 1. Load data\n",
    "X_sonar, y_sonar = load_sonar()\n",
    "print(\"Sonar dataset loaded.\")\n",
    "\n",
    "# --- EXERCISE REQUIREMENTS --- \n",
    "# 1. Define RepeatedStratifiedKFold.\n",
    "# 2. Create a Pipeline with:\n",
    "#    a. ('p', PolynomialFeatures(degree=2, include_bias=False))\n",
    "#    b. ('m', KNeighborsClassifier())\n",
    "# 3. Evaluate and print the mean accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6db108",
   "metadata": {},
   "source": [
    "### Knowledge Check (Problem 12)\n",
    "\n",
    "**Question 1:** What does `PolynomialFeatures(degree=2)` do? If the input has 2 features [a, b], what will the output be?\n",
    "\n",
    "**Question 2:** Why is this helpful for models like `KNeighborsClassifier` or `LogisticRegression`?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a66377",
   "metadata": {},
   "source": [
    "### Dataset Introduction: Abalone\n",
    "\n",
    "This is a popular regression dataset. The goal is to predict the age of an abalone (target variable 'Rings') based on 8 physical features.\n",
    "\n",
    "This dataset is a classic example of mixed-type data: it contains 7 numerical features (length, diameter, weight...) and 1 categorical feature (column 'Sex': 'M', 'F', 'I'). This makes it ideal for testing `ColumnTransformer`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581de0b0",
   "metadata": {},
   "source": [
    "## --- Problem 13: Handle Mixed-Type Data with ColumnTransformer ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ffb330",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Problem 13: Abalone (ColumnTransformer) ---\")\n",
    "# 1. Load data\n",
    "X_abalone, y_abalone = load_abalone()\n",
    "y_abalone = y_abalone.astype(int)\n",
    "print(\"Abalone dataset loaded successfully.\")\n",
    "\n",
    "# --- EXERCISE REQUIREMENTS --- \n",
    "# 1. Identify the column indices: categorical_features_idx = [0] and numerical_features_idx = list(range(1, X_abalone.shape[1])).\n",
    "# 2. Create a ColumnTransformer:\n",
    "#    a. Apply ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features_idx)\n",
    "#    b. Apply ('num', MinMaxScaler(), numerical_features_idx)\n",
    "# 3. Create a Pipeline with:\n",
    "#    a. ('trans', [Your ColumnTransformer])\n",
    "#    b. ('m', SVR(gamma='scale'))\n",
    "# 4. Define RepeatedKFold (for regression).\n",
    "# 5. Evaluate the pipeline (scoring='neg_mean_absolute_error') and print the MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1359d87",
   "metadata": {},
   "source": [
    "### Knowledge Check (Problem 13)\n",
    "\n",
    "**Question 1:** What is the main purpose of `ColumnTransformer`?\n",
    "\n",
    "**Question 2:** What does `OneHotEncoder` transform the 'Sex' column (with 3 values 'M', 'F', 'I') into?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74d735c",
   "metadata": {},
   "source": [
    "### Dataset Introduction: California Housing\n",
    "\n",
    "This is a famous regression dataset from the 1990 California census. \n",
    "\n",
    "The goal is to predict the median house value for California districts. The features (e.g., median income, house age, num rooms...) are all numerical. The target variable (house value) has a skewed distribution, making it a good example for `TransformedTargetRegressor`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e5f3eb",
   "metadata": {},
   "source": [
    "## --- Problem 14: Apply a Transform to the Target Variable ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db56ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Problem 14: Housing (Regression) - Target Transform ---\")\n",
    "# 1. Load data\n",
    "housing = fetch_california_housing()\n",
    "X_housing, y_housing = housing.data, housing.target\n",
    "print(\"California Housing dataset loaded successfully.\")\n",
    "\n",
    "# --- EXERCISE REQUIREMENTS --- \n",
    "# 1. Define RepeatedKFold.\n",
    "# 2. (For comparison) Create and evaluate a baseline Pipeline: (MinMaxScaler(), HuberRegressor()). Print its MAE.\n",
    "# 3. (Main Task) Create a pipeline for the 'regressor': model_tt = Pipeline(steps=[('s', MinMaxScaler()), ('m', HuberRegressor())])\n",
    "# 4. Create a 'transformer' for y: y_transformer = MinMaxScaler()\n",
    "# 5. Create the final pipeline: pipeline_tt = TransformedTargetRegressor(regressor=model_tt, transformer=y_transformer)\n",
    "# 6. Evaluate pipeline_tt (scoring='neg_mean_absolute_error') and print its MAE.\n",
    "# 7. (Optional) Plot a boxplot to compare the baseline pipeline and the pipeline_tt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dd1dc0",
   "metadata": {},
   "source": [
    "### Knowledge Check (Problem 14)\n",
    "\n",
    "**Question 1:** What does `TransformedTargetRegressor` do to the `y` variable (house price)?\n",
    "\n",
    "**Question 2:** Why would we want to scale the `y` variable?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba92a3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- All Exercises Completed ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-teaching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
